<!DOCTYPE HTML>
<html lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Anqi Li</title>
  <meta name="author" content="Anqi Li">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
</head>

<body>
  <div class="page-wrapper">
    <div class="container">
      <table class="main-table">
        <tbody>
          <tr>
            <td>
              <table class="header-table">
                <tbody>
                  <tr>
                    <td class="profile-text">
                      <h1>Anqi Li | ÊùéÂÆâÈΩê</h1>
                      <p>
                        Hi, I am a junior undergraduate student at Yuanpei College, Peking University, majoring in Artificial Intelligence. </br>
                        I'm currently working in the <a href="https://pku-epic.github.io/">EPIC Lab</a> under the supervision of <a href="https://hughw19.github.io/">Prof. He Wang</a> 
                        and working closely with <a href="https://jzhzhang.github.io/">Jiazhao Zhang</a>. 
                        I focus on embodied AI, particularly Vision-Language-Action (VLA) models and their applications in robotic navigation and mobile manipulation.<br>
                      </p>
                      <div class="social-links">
                        <a href="mailto:lianqi0417@stu.pku.edu.cn"><i class="fas fa-envelope"></i> Email</a>
                        <a href="https://github.com/andyhandsom6"><i class="fab fa-github"></i> GitHub</a>
                        <a href="https://scholar.google.com/citations?user=bnqOtxcAAAAJ&hl=en&oi=sra"><i class="fas fa-graduation-cap"></i> Google Scholar</a>
                        <a href="./docs/CV_Anqi_Li.pdf"><i class="fas fa-file-alt"></i> CV</a>
                        <!-- Additional links can be added here -->
                      </div>
                    </td>
                    <td class="profile-img">
                      <div class="img-container">
                        <a href="images/anqi/Anqi.jpg">
                          <img src="images/anqi/Anqi.jpg" alt="Anqi Li">
                        </a>
                      </div>
                    </td>
                  </tr>
                </tbody>
              </table>
              
              <div class="section">
                <h2><i class="fas fa-newspaper"></i> News</h2>
              </div>

              <div class="news">
                <ul class="news-list">
                  <!-- Add / edit news items here -->
                  <li><span class="news-date">2025.11</span><span class="news-dot">‚Ä¢</span>I am joining UC Berkeley as a visiting student in Spring 2026. Feel free to reach out to chat or collaborate! </li>
                  <li><span class="news-date">2025.11</span><span class="news-dot">‚Ä¢</span>I gave an <strong><a href="https://mp.weixin.qq.com/s/vy6qmKXqoHwb3gB3oxEyuQ">invited talk</a></strong> at Yuanpei College, Peking University, introducing my work on urban micromobility. </li>
                  <li><span class="news-date">2025.08</span><span class="news-dot">‚Ä¢</span>üéâ <strong>TrackVLA</strong> gets accepted to <strong>CoRL 2025</strong>.</li>
                </ul>
              </div>

              <div class="section">
                <h2><i class="fas fa-flask"></i> Research</h2>
              </div>
              
              <table class="research-table">
                <tbody class="research-item highlight">
                  <tr>
                    <td class="research-img">
                      <div class="img-hover-container">
                        <div class="static-img">
                          <img src='images/urbanvla/teaser.jpeg' alt="UrbanVLA static">
                        </div>
                        <div class="animated-img">
                          <img src="images/urbanvla/urbanvla.gif" alt="UrbanVLA animation">
                        </div>
                      </div>
                    </td>
                    <td class="research-details">
                      <a href="https://pku-epic.github.io/UrbanVLA-Web/">
                        <h3>UrbanVLA: A Vision-Language-Action Model for Urban Micromobility</h3>
                      </a>
                      <div class="authors">
                        <strong>Anqi Li*</strong>, Zhiyong Wang*, Jiazhao Zhang*, Minghan Li, 
                        Yunpeng Qi, Zhibo Chen, Zhizheng Zhang<sup>‚Ä†</sup>, He Wang<sup>‚Ä†</sup>
                      </div>
                      <div class="pub-info">
                        <em><strong>arXiv preprint</strong></em>
                      </div>
                      <div class="links">
                        <a href="https://arxiv.org/pdf/2510.23576"><i class="fas fa-file-pdf"></i> Paper</a>
                        <!-- <a href="https://github.com/wsakobe/TrackVLA"><i class="fas fa-code"></i> Code</a> -->
                        <a href="https://pku-epic.github.io/UrbanVLA-web/"><i class="fas fa-link"></i> Project page</a>
                      </div>
                      <p>
                        UrbanVLA is a route-conditioned Vision-Language-Action model for urban micromobility. It aligns high-level navigation routes with visual observations to enable scalable, long-horizon navigation. 
                        <!-- Trained via a two stage pipeline including SFT and RFT, UrbanVLA outperforms baselines by over 55% on MetaUrban and achieves robust real-world navigation across 500m+ routes. -->
                      </p>
                    </td>
                  </tr>
                </tbody>
                <tbody class="research-item highlight">
                  <tr>
                    <td class="research-img">
                      <div class="img-hover-container">
                        <div class="static-img">
                          <img src='images/navfom/teaser.png' alt="NavFOM static">
                        </div>
                        <div class="animated-img">
                          <img src="images/navfom/demo.gif" alt="NavFOM animation">
                        </div>
                      </div>
                    </td>
                    <td class="research-details">
                      <a href="https://pku-epic.github.io/NavFoM-Web/">
                        <h3>Embodied Navigation Foundation Model</h3>
                      </a>
                      <div class="authors">
                        Jiazhao Zhang*, <strong>Anqi Li*</strong>, Yunpeng Qi*, Minghan Li*, Jiahang Liu,  
                        Shaoan Wang, Haoran Liu, Gengze Zhou, Yuze Wu, Xingxing Li, Yuxin Fan,  
                        Wenjun Li, Zhibo Chen, Fei Gao, Qi Wu, Zhizheng Zhang<sup>‚Ä†</sup>, He Wang<sup>‚Ä†</sup>
                      </div>
                      <div class="pub-info">
                        <em><strong>arXiv preprint</strong></em>
                      </div>
                      <div class="links">
                        <a href="https://arxiv.org/pdf/2509.12129"><i class="fas fa-file-pdf"></i> Paper</a>
                        <!-- <a href="https://github.com/wsakobe/TrackVLA"><i class="fas fa-code"></i> Code</a> -->
                        <a href="https://pku-epic.github.io/NavFoM-web/"><i class="fas fa-link"></i> Project page</a>
                      </div>
                      <p>
                        NavFoM is a cross-embodiment and cross-task navigation model trained on 8 million samples encompassing quadrupeds, drones, wheeled robots, and vehicles, spanning tasks including vision-and-language navigation, object searching, target tracking, and autonomous driving.
                      </p>
                    </td>
                  </tr>
                </tbody>
                <tbody class="research-item">
                  <tr>
                    <td class="research-img">
                      <div class="img-hover-container">
                        <div class="static-img">
                          <img src='images/trackvla/trackvla.png' alt="TrackVLA static">
                        </div>
                        <div class="animated-img">
                          <img src="images/trackvla/trackvla.gif" alt="TrackVLA animation">
                        </div>
                      </div>
                    </td>
                    <td class="research-details">
                      <a href="https://pku-epic.github.io/TrackVLA-web/">
                        <h3>TrackVLA: Embodied Visual Tracking in the Wild</h3>
                      </a>
                      <div class="authors">
                        Shaoan Wang*, Jiazhao Zhang*, Minghan Li, Jiahang Liu, 
                        <strong>Anqi Li</strong>, Kui Wu, Fangwei Zhong, Junzhi Yu, 
                        Zhizheng Zhang<sup>‚Ä†</sup>, He Wang<sup>‚Ä†</sup>
                      </div>
                      <div class="pub-info">
                        <em><strong>CoRL 2025</strong></em>
                      </div>
                      <div class="links">
                        <a href="https://arxiv.org/pdf/2505.23189"><i class="fas fa-file-pdf"></i> Paper</a>
                        <a href="https://github.com/wsakobe/TrackVLA"><i class="fas fa-code"></i> Code</a>
                        <a href="https://pku-epic.github.io/TrackVLA-web/"><i class="fas fa-link"></i> Project page</a>
                      </div>
                      <p>
                        TrackVLA is a vision-language-action model capable of simultaneous object recognition and visual tracking, trained on a dataset of 1.7 million samples. It demonstrates robust tracking, long-horizon tracking, and cross-domain generalization across diverse challenging environments.
                      </p>
                    </td>
                  </tr>
                </tbody>
              </table>

              <div class="section">
                <h2><i class="fas fa-briefcase"></i> Experience</h2>
              </div>
              
              <table class="experience-table">
                <tbody>
                  <tr>
                    <td class="logo-cell">
                      <div class="logo-container">
                        <img src="images/logos/uc_berkeley.png" alt="UC Berkeley">
                      </div>
                    </td>
                    <td class="exp-details">
                      <h3>University of California, Berkeley</h3>
                      <div class="exp-meta">
                        <span>U.S.</span>
                        <span>Upcoming</span>
                      </div>
                      <p><strong>Visiting Student</strong></p>
                      <!-- <p>Research Advisor: Prof. <a href="https://me.berkeley.edu/people/masayoshi-tomizuka/">Masayoshi Tomizuka</a></p> -->
                    </td>
                  </tr>
                </tbody>
                <tbody>
                  <tr>
                    <td class="logo-cell">
                      <div class="logo-container">
                        <img src="images/logos/galbot.png" alt="Galbot">
                      </div>
                    </td>
                    <td class="exp-details">
                      <h3>Galbot</h3>
                      <div class="exp-meta">
                        <span>China</span>
                        <span>2024.09 - Present</span>
                      </div>
                      <p><strong>Research Intern</strong></p>
                      <p>Research Advisor: Prof. <a href="https://hughw19.github.io/">He Wang</a>, Dr. <a href="https://scholar.google.com/citations?user=X7M0I8kAAAAJ&hl=en">Zhizheng Zhang</a></p>
                    </td>
                  </tr>
                </tbody>
                <tbody>
                  <tr>
                    <td class="logo-cell">
                      <div class="logo-container">
                        <img src="images/logos/peking_university.png" alt="Peking University">
                      </div>
                    </td>
                    <td class="exp-details">
                      <h3>Peking University</h3>
                      <div class="exp-meta">
                        <span>China</span>
                        <span>2023.09 - Present</span>
                      </div>
                      <p><strong>Undergraduate Student</strong></p>
                      <p>Major: Intelligence Science and Technology @ <a href="https://yuanpei.pku.edu.cn/en/">Yuanpei College</a><br>
                        Minor: Innovation and Entrepreneurship Management @ <a href="https://en.gsm.pku.edu.cn/">Guanghua School of Management</a></p>
                    </td>
                  </tr>
                </tbody>
              </table>
              
              <div class="section">
                <h2><i class="fas fa-icons"></i> Miscellaneous</h2>
              </div>

              <div class="misc">
                <p>
                  Outside of research, I have several hobbies. 
                </p>
                <ul class="misc-bullets">
                  <li>I enjoy playing basketball, and I am a huge fan of the NBA. My favorite player is Luka Donƒçiƒá. </li>
                  <li>I love performing on the trombone. I am an active member of the Symphony Orchestra at my high school, Experimental High School attached to Beijing Normal University. Check out our <a href="https://www.bilibili.com/video/BV1Rx2MB8EEm">recent performance</a>.</li>
                  <li>I am a speedcuber. I participated in several speedcubing competitions held by the World Cube Association (WCA). Check out my <a href="https://www.worldcubeassociation.org/persons/2018LIAN42">WCA personal profile</a>.</li>
                </ul>
              </div>

              <div class="footer">
                <p>
                  Webpage template adapted from <a href="https://jonbarron.info/">Jon Barron</a>.
                  <br> Last updated: Dec., 2025
                </p>
              </div>
            </td>
          </tr>
        </tbody>
      </table>
    </div>
  </div>
</body>
</html>